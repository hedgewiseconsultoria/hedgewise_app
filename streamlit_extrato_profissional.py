import os
import json
import streamlit as st
import pandas as pd
from google import genai
from google.genai import types
from io import BytesIO

# IMPORTA√á√ïES ESSENCIAIS DO SEU C√ìDIGO ORIGINAL
from extrato_parser import extrair_texto_pdf, processar_extrato_principal

# -------------------------------------------------
# Configura√ß√£o do Streamlit
# -------------------------------------------------
st.set_page_config(page_title="Hedgewise - Extrato Profissional", layout="wide")
st.title("An√°lise de Extrato Banc√°rio com IA")

# 1. AJUSTE: Permite m√∫ltiplos arquivos
uploaded_files = st.file_uploader(
    "üìé Envie os extratos banc√°rios em PDF (m√∫ltiplos arquivos permitidos)",
    type=["pdf"],
    accept_multiple_files=True  # <--- MUDAN√áA PRINCIPAL
)

# Inicializa uma lista para armazenar todos os resultados classificados
todos_dados_classificados = []

# -------------------------------------------------
# L√≥gica de processamento (In√≠cio)
# -------------------------------------------------
if uploaded_files:
    
    # Adiciona o bot√£o de processamento
    if st.button("üöÄ Iniciar Processamento Universal das Transa√ß√µes"):
        
        API_KEY = os.getenv("GEMINI_API_KEY")
        if not API_KEY:
            st.error("Chave da API do Gemini (GEMINI_API_KEY) n√£o configurada.")
            st.stop()
        
        try:
            client = genai.Client(api_key=API_KEY)
        except Exception as e:
            st.error(f"Erro ao inicializar o cliente Gemini: {e}")
            st.stop()

        
        # 2. AJUSTE: LOOP SOBRE CADA ARQUIVO ENVIADO
        for i, uploaded_file in enumerate(uploaded_files):
            file_name = uploaded_file.name
            st.subheader(f"üìÇ Processando Arquivo {i+1} de {len(uploaded_files)}: {file_name}")
            
            pdf_bytes = uploaded_file.read()
            pdf_stream = BytesIO(pdf_bytes)

            # --- PARTE 1: EXTRA√á√ÉO E NORMALIZA√á√ÉO (extrato_parser.py) ---
            
            # A extra√ß√£o de texto ainda √© importante para debug e inspe√ß√£o
            try:
                # O seek(0) √© crucial para garantir que o stream comece do in√≠cio
                # A fun√ß√£o extrair_texto_pdf far√° a leitura inicial
                pdf_stream.seek(0)
                texto = extrair_texto_pdf(pdf_stream)
            except Exception as e:
                st.error(f"Erro ao ler PDF de {file_name}: {e}. Pulando para o pr√≥ximo.")
                continue

            if not texto or len(texto.strip()) < 50:
                st.warning(f"Nenhum texto leg√≠vel foi extra√≠do de {file_name}. Pulando.")
                continue

            with st.expander(f"üìÑ Texto extra√≠do de {file_name}"):
                st.text_area(f"Conte√∫do do extrato {file_name}:", texto, height=200)

            st.info("Iniciando processamento universal (Best-Effort) de transa√ß√µes...")

            # Chama a fun√ß√£o mestra que executa todos os processadores e escolhe o melhor DF
            # Precisa garantir que o stream esteja no in√≠cio novamente antes de chamar
            pdf_stream.seek(0) 
            df_transacoes = processar_extrato_principal(pdf_stream)

            if df_transacoes.empty:
                st.warning(f"N√£o foi poss√≠vel identificar movimenta√ß√µes financeiras v√°lidas em {file_name}.")
                continue
                
            if 'Tipo' not in df_transacoes.columns:
                st.error(f"A coluna 'Tipo' (D/C) n√£o foi gerada para {file_name}. Pulando.")
                continue

            st.success(f"Transa√ß√µes Extra√≠das de {file_name}: {len(df_transacoes)}")
            # Opcional: mostrar as transa√ß√µes extra√≠das por arquivo
            # st.dataframe(df_transacoes, use_container_width=True)


            # --- PARTE 2: CLASSIFICA√á√ÉO GEMINI (LOOP DE LOTE) ---

            TAMANHO_DO_LOTE = 50 
            dados_classificados_lote = []
            
            # JSON SCHEMA ATUALIZADO (mantido)
            json_schema = {
                "type": "array",
                "items": {
                    "type": "object",
                    "properties": {
                        "data": {"type": "string", "description": "A data da transa√ß√£o."},
                        "historico": {"type": "string", "description": "O hist√≥rico ou descri√ß√£o original da transa√ß√£o."},
                        "valor": {"type": "string", "description": "O valor original da transa√ß√£o."},
                        "tipo": {"type": "string", "description": "O tipo original da transa√ß√£o ('D' para d√©bito, 'C' para cr√©dito)."},
                        "natureza_geral": {"type": "string", "description": "Classifica√ß√£o PRINCIPAL em 'Despesa' ou 'Receita'."},
                        "subgrupo": {"type": "string", "description": "Classifica√ß√£o DFC/CPC 03: 'Operacional', 'Investimento', 'Financiamento' ou 'Pessoal'."},
                        "natureza_analitica": {"type": "string", "description": "Classifica√ß√£o detalhada e linear da transa√ß√£o (Ex: 'Sal√°rio', 'Aluguel', 'Fornecedores')."},
                        "natureza_juridica": {"type": "string", "description": "Classifica√ß√£o 'Pessoal' ou 'Empresarial'."}
                    },
                    "required": ["data", "historico", "valor", "tipo", "natureza_geral", "subgrupo", "natureza_analitica", "natureza_juridica"]
                }
            }
            
            config = types.GenerateContentConfig(
                response_mime_type="application/json",
                response_schema=json_schema,
                temperature=0.1, 
                thinking_config=types.ThinkingConfig(thinking_budget=0) 
            )

            st.info(f"Analisando {len(df_transacoes)} transa√ß√µes de {file_name} com taxonomia CPC 03...")

            n_batches = len(df_transacoes) // TAMANHO_DO_LOTE + (1 if len(df_transacoes) % TAMANHO_DO_LOTE > 0 else 0)
            progress_bar = st.progress(0, text=f"Iniciando o processamento dos lotes de {file_name}...")
            
            for j in range(n_batches):
                start_index = j * TAMANHO_DO_LOTE
                end_index = start_index + TAMANHO_DO_LOTE
                lote_df = df_transacoes.iloc[start_index:end_index]
                
                texto_formatado_lote = "\n".join(
                    f"{row.Data} | {row['Hist√≥rico']} | {row['Valor']} | Tipo: {row['Tipo']}"
                    for _, row in lote_df.iterrows()
                )

                prompt_lote = f"""
Voc√™ √© um analista financeiro s√™nior da Hedgewise, especializado na composi√ß√£o da Demonstra√ß√£o de Fluxo de Caixa (DFC) conforme o CPC 03 (IAS 7).

Sua tarefa √© analisar AS {len(lote_df)} MOVIMENTA√á√ïES BANC√ÅRIAS extra√≠das de "{file_name}" e retornar um JSON estritamente conforme o schema fornecido.

**Instru√ß√µes de Classifica√ß√£o (Obrigat√≥rias):**

1.  **natureza_geral** (Grupo): Classifique estritamente como **"Receita"** ou **"Despesa"**. (Observar se o Tipo original √© 'C'r√©dito ou 'D'√©bito, mas sempre priorizar o significado da transa√ß√£o).
2.  **subgrupo** (DFC/CPC 03): Classifique estritamente em uma das quatro op√ß√µes:
    * **"Operacional"**: Transa√ß√µes que afetam o resultado e o capital de giro (vendas, compras, sal√°rios, alugu√©is, impostos, fornecedores, etc.).
    * **"Investimento"**: Aquisi√ß√£o ou venda de ativos n√£o circulantes (im√≥veis, m√°quinas, participa√ß√µes societ√°rias), desembolsos com aplica√ß√µes financeiras, resgates de aplica√ß√µes financeiras, rendimentos de aplica√ß√µes financeiras.
    * **"Financiamento"**: Transa√ß√µes com capital de terceiros ou pr√≥prio (empr√©stimos, integraliza√ß√£o/distribui√ß√£o de capital, dividendos), pagamentos de juros, tarifas banc√°rias, pagamentos de empr√©stimos, recebimento de empr√©stimos.
    * **"Pessoal"**: Despesas pessoais do s√≥cio/empreendedor pagas pela conta da empresa (retiradas, despesas particulares, etc.), gastos que fujam da l√≥gica do contexto empresarial.
3.  **natureza_analitica** (Subgrupo Detalhado):
    * Identifique o destino/origem de forma detalhada e linear.
    * **REGRA DE PREENCHIMENTO:** Se o hist√≥rico for gen√©rico (ex: "Pagamento de Boleto", "Transfer√™ncia TED", "Pix") e n√£o houver informa√ß√£o clara, assuma **"Fornecedores"** ou **"Despesas Gerais Operacionais"** se for um d√©bito, e **"Vendas/Servi√ßos"** se for um cr√©dito, pois a premissa √© que a conta √© empresarial.
4.  **natureza_juridica**: Classifique estritamente como **"Empresarial"** ou **"Pessoal"**.

Responda APENAS com o JSON.

Movimenta√ß√µes extra√≠das:
{texto_formatado_lote}
                """
                
                progress_bar.progress((j + 1) / n_batches, text=f"Lote {j+1} de {n_batches} para {file_name}...")
                
                try:
                    response = client.models.generate_content(
                        model='gemini-2.5-flash',
                        contents=prompt_lote,
                        config=config,
                    )
                    resposta_texto = response.text
                    dados_lote = json.loads(resposta_texto)
                    
                    if isinstance(dados_lote, list):
                        # Adiciona o nome do arquivo a cada transa√ß√£o para identificar a origem
                        for transacao in dados_lote:
                            transacao['arquivo_origem'] = file_name
                        dados_classificados_lote.extend(dados_lote)
                    else:
                        st.warning(f"Lote {j+1} de {file_name}: Retorno JSON inesperado. Ignorado.")

                except json.JSONDecodeError:
                    st.error(f"Lote {j+1} de {file_name} falhou. Verifique a resposta bruta abaixo.")
                    # st.text_area(f"Resposta bruta do Lote {j+1} de {file_name}:", resposta_texto, height=150)
                except Exception as e:
                    st.error(f"Erro na chamada da API para {file_name}, lote {j+1}: {e}")
                    
            progress_bar.empty()
            st.success(f"‚úÖ Classifica√ß√£o de {file_name} conclu√≠da.")
            
            # Adiciona os resultados deste arquivo √† lista total
            todos_dados_classificados.extend(dados_classificados_lote)

        # -------------------------------------------------
        # Exibir Resultado Final GLOBAL
        # -------------------------------------------------
        st.subheader("üìä Resultado Final da IA (Extrato Classificado) - Consolida√ß√£o")

        if todos_dados_classificados:
            
            st.success(f"Processamento de todos os arquivos conclu√≠do! Total de {len(todos_dados_classificados)} transa√ß√µes classificadas.")

            st.subheader("Tabela Classificada Completa")
            df_classificado = pd.DataFrame(todos_dados_classificados)
            
            # Reorganiza as colunas e inclui a nova coluna de origem
            colunas_ordenadas = [
                'arquivo_origem', 'data', 'historico', 'valor', 'tipo', 
                'natureza_geral', 'subgrupo', 'natureza_analitica', 'natureza_juridica'
            ]
            df_classificado = df_classificado[colunas_ordenadas]
            
            st.dataframe(df_classificado, use_container_width=True)
            
            # Opcional: Adicionar um bot√£o de download
            @st.cache_data
            def convert_df_to_csv(df):
                return df.to_csv(index=False).encode('utf-8')

            csv = convert_df_to_csv(df_classificado)
            st.download_button(
                label="‚¨áÔ∏è Baixar Tabela Completa (CSV)",
                data=csv,
                file_name='extratos_classificados_consolidado.csv',
                mime='text/csv',
            )
            
        else:
            st.warning("Nenhum dado classificado foi retornado ap√≥s o processamento de todos os arquivos. Verifique os erros acima.")
